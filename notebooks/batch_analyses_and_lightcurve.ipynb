{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13c1f1e",
   "metadata": {},
   "source": [
    "# REMIR Light Curve Extraction\n",
    "\n",
    "Extract multi-band light curves from REMIR pipeline photometry output files.\n",
    "\n",
    "## How it works\n",
    "\n",
    "1. Scans all `*_photometry.txt` files inside the `reduced/` folder\n",
    "2. Parses every header field (OBJECT, DATE-OBS, EXPTIME, filter, image type, zeropoint, RMS, quality flags, limiting magnitude, calibration star count, rejection fraction)\n",
    "3. Cross-matches the source list against your target coordinates within a configurable radius\n",
    "4. Reads all source columns including instrumental/catalog magnitudes and quality flags (isolated, crowded, border)\n",
    "5. Classifies each epoch as **detection** or **upper limit** (limiting magnitude)\n",
    "6. Outputs a time-sorted CSV and DataFrame ready for plotting\n",
    "\n",
    "## Input modes\n",
    "\n",
    "**Single night** — point `INPUT_FOLDER` directly to the pipeline output folder:\n",
    "\n",
    "```python\n",
    "INPUT_FOLDER = \"/path/to/20260115/proc\"\n",
    "RECURSIVE    = False\n",
    "```\n",
    "\n",
    "Expected structure:\n",
    "\n",
    "```\n",
    "proc/\n",
    "└── reduced/\n",
    "    ├── OGLE-0204_334100_1_H_astro_photometry.txt\n",
    "    ├── OGLE-0204_334100_2_J_astro_photometry.txt\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "With the usual pipeline run (assuming you are in the right folder):\n",
    "\n",
    "```bash\n",
    "python remirpipe.py -i . -o proc -s -v -co (-t OBJECT_NAME)\n",
    "```\n",
    "\n",
    "**Multiple nights** — point `INPUT_FOLDER` to the parent and enable recursion:\n",
    "\n",
    "```python\n",
    "INPUT_FOLDER = \"/path/to/all_nights\"\n",
    "RECURSIVE    = True\n",
    "```\n",
    "\n",
    "Expected structure:\n",
    "\n",
    "```\n",
    "all_nights/\n",
    "├── 20260115/proc/reduced/*.txt\n",
    "├── 20260116/proc/reduced/*.txt\n",
    "└── ...\n",
    "```\n",
    "\n",
    "Batch-process many nights first:\n",
    "\n",
    "```bash\n",
    "cd all_nights/\n",
    "for dir in */; do\n",
    "    echo \"========== Processing: $dir ==========\"\n",
    "    python remirpipe.py -i \"$dir\" -o \"$dir\"/proc -s -v -co (-t OBJECT_NAME)\n",
    "done\n",
    "```\n",
    "\n",
    "## Source matching\n",
    "\n",
    "For each photometry file the script finds the **closest source** within `TOLERANCE_ARCSEC` of the target coordinates. All 11 columns from the photometry catalog are read:\n",
    "\n",
    "| Column | Index | Description |\n",
    "|--------|-------|-------------|\n",
    "| `ra` | 0 | Right Ascension [deg] |\n",
    "| `dec` | 1 | Declination [deg] |\n",
    "| `x` | 2 | Pixel X position |\n",
    "| `y` | 3 | Pixel Y position |\n",
    "| `mag_inst` | 4 | Instrumental magnitude |\n",
    "| `e_mag_inst` | 5 | Instrumental magnitude error |\n",
    "| `mag_cat` | 6 | 2MASS catalog magnitude (`-99` if no match) |\n",
    "| `e_mag_cat` | 7 | 2MASS catalog magnitude error (`-99` if no match) |\n",
    "| `mag_cal` | 8 | Calibrated magnitude (`mag_inst + ZP`) |\n",
    "| `e_mag_cal` | 9 | Calibrated magnitude error |\n",
    "| `flag` | 10 | Quality flag |\n",
    "\n",
    "### Quality flags\n",
    "\n",
    "| Flag | Label | Meaning |\n",
    "|------|-------|---------|\n",
    "| 0 | `isolated+central` | Best quality — isolated source, away from edges |\n",
    "| 1 | `crowded` | Nearby neighbours within minimum separation |\n",
    "| 2 | `border` | Close to image edge |\n",
    "| 3 | `crowded+border` | Both crowded and near edge — worst quality |\n",
    "\n",
    "The flag is stored in the output as `flag` and two boolean convenience columns:\n",
    "\n",
    "- `is_crowded` — `True` if flag is 1 or 3\n",
    "- `is_border` — `True` if flag is 2 or 3\n",
    "\n",
    "## Image type\n",
    "\n",
    "The pipeline tags each photometry file with the image type:\n",
    "\n",
    "- **`COADD`** — co-added image (inverse-variance weighted mean of N aligned frames). The number of frames is stored in `ncoadd`.\n",
    "- **`SINGLE`** — individual aligned frame (one dither position).\n",
    "\n",
    "This lets you filter the light curve to use only coadds (deeper, better S/N) or include single frames (more time resolution).\n",
    "\n",
    "## Detection vs upper limit logic\n",
    "\n",
    "```\n",
    "Source found within TOLERANCE_ARCSEC?\n",
    "├── YES ─── e_mag_cal ≤ MAX_MAG_ERROR? ─── YES → DETECTION\n",
    "│                                      └── NO  → UPPER LIMIT (Limiting_mag)\n",
    "└── NO  ─── Limiting_mag available? ─── YES → UPPER LIMIT (Limiting_mag)\n",
    "                                    └── NO  → SKIPPED (not in output)\n",
    "```\n",
    "\n",
    "Upper limits have `is_detection = False`, `mag_cal = Limiting_mag`, `e_mag_cal = 0.0`.\n",
    "\n",
    "## Output columns\n",
    "\n",
    "### From the header\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| `OBJECT` | Target name |\n",
    "| `DATE_OBS` | Observation timestamp (ISO format) |\n",
    "| `EXPTIME` | Exposure time [s] |\n",
    "| `Filter` | Photometric band (J / H / K) |\n",
    "| `image_type` | `COADD` or `SINGLE` |\n",
    "| `ncoadd` | Number of coadded frames (only for coadds) |\n",
    "| `Zeropoint` | Photometric zeropoint [mag] |\n",
    "| `ZP_err` | Zeropoint uncertainty [mag] |\n",
    "| `RMS_residuals` | Zeropoint fit RMS [mag] |\n",
    "| `RMS_quality` | VERY GOOD / GOOD / MEDIUM / POOR / VERY POOR |\n",
    "| `ZP_check` | Zeropoint consistency flag |\n",
    "| `Calibration_stars` | Number of 2MASS stars used |\n",
    "| `Stars_rejected_frac` | Fraction rejected (e.g. 0.036 = 3.6%) |\n",
    "| `Rejection_quality` | GOOD / MEDIUM / POOR |\n",
    "| `Limiting_mag` | 3σ limiting magnitude [mag] |\n",
    "\n",
    "### From the source match\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| `mag_cal` | Calibrated magnitude (or limiting mag for upper limits) |\n",
    "| `e_mag_cal` | Magnitude error (0.0 for upper limits) |\n",
    "| `mag_inst` | Instrumental magnitude |\n",
    "| `e_mag_inst` | Instrumental magnitude error |\n",
    "| `mag_cat` | 2MASS catalog magnitude (`-99` if unmatched) |\n",
    "| `e_mag_cat` | 2MASS catalog error (`-99` if unmatched) |\n",
    "| `x`, `y` | Pixel position on image |\n",
    "| `flag` | Quality flag (0/1/2/3) |\n",
    "| `is_crowded` | `True` if crowded (flag 1 or 3) |\n",
    "| `is_border` | `True` if near border (flag 2 or 3) |\n",
    "| `is_detection` | `True` = detection, `False` = upper limit |\n",
    "| `separation_arcsec` | Distance to target [arcsec] |\n",
    "\n",
    "### Computed time columns\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| `datetime` | Python datetime object |\n",
    "| `MJD` | Modified Julian Date |\n",
    "| `MJD_rel` | Days since first epoch |\n",
    "| `hours_rel` | Hours since first epoch |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract a light curve from REMIR pipeline photometry files.\n",
    "\n",
    "Searches *_photometry.txt in reduced/ folders, cross-matches each\n",
    "source list against a target position, and returns a time-sorted DataFrame.\n",
    "\n",
    "Set RECURSIVE = False for a single night folder, True for multi-night trees.\n",
    "Optionally filters by OBJECT name(s) from the photometry header.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.time import Time\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration — edit these for your target\n",
    "# =============================================================================\n",
    "\n",
    "INPUT_FOLDER     = \"path/to/your/folder\"   # single night: the proc/ dir\n",
    "                                            # multi night:  the parent dir\n",
    "RECURSIVE        = False                    # False = single folder\n",
    "                                            # True  = recurse into subfolders\n",
    "\n",
    "TARGET_RA        = 255.70578               # target Right Ascension  [deg]\n",
    "TARGET_DEC       = -48.78975               # target Declination      [deg]\n",
    "TOLERANCE_ARCSEC = 1.0                     # cross-match radius      [arcsec]\n",
    "MAX_MAG_ERROR    = 0.33                    # errors above this → upper limit\n",
    "OUTPUT_CSV       = \"photometry_results.csv\"\n",
    "\n",
    "# Filter by OBJECT keyword.\n",
    "#   TARGET_OBJECTS = [\"GX_339-4\"]           → keep only this object\n",
    "#   TARGET_OBJECTS = [\"SN2026acd\", \"M31\"]   → keep two objects\n",
    "#   TARGET_OBJECTS = None                   → accept everything\n",
    "TARGET_OBJECTS   = None\n",
    "\n",
    "# Filter by image type.\n",
    "#   IMAGE_TYPES = [\"COADD\"]                → coadds only (deeper, fewer points)\n",
    "#   IMAGE_TYPES = [\"SINGLE\"]               → single frames only (more time resolution)\n",
    "#   IMAGE_TYPES = [\"COADD\", \"SINGLE\"]      → both\n",
    "#   IMAGE_TYPES = None                     → accept everything (same as both)\n",
    "IMAGE_TYPES      = None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Parser\n",
    "# =============================================================================\n",
    "\n",
    "def parse_photometry_file(filepath, target_ra, target_dec,\n",
    "                          tolerance_arcsec, max_mag_error=0.33,\n",
    "                          target_objects=None, image_types=None):\n",
    "    \"\"\"Parse one *_photometry.txt and return metadata + matched photometry.\n",
    "\n",
    "    Returns None if the file cannot be read, has no OBJECT match (when\n",
    "    *target_objects* is set), image type doesn't match (when *image_types*\n",
    "    is set), or contains no usable photometry.\n",
    "    \"\"\"\n",
    "    rec = dict(\n",
    "        filename=os.path.basename(filepath),\n",
    "        # ── header fields ──\n",
    "        OBJECT=None, DATE_OBS=None, EXPTIME=None, Filter=None,\n",
    "        image_type=None, ncoadd=None,\n",
    "        Zeropoint=None, ZP_err=None, RMS_residuals=None, RMS_quality=None,\n",
    "        ZP_check=None, Calibration_stars=None, Stars_rejected_frac=None,\n",
    "        Rejection_quality=None, Limiting_mag=None,\n",
    "        # ── source match fields ──\n",
    "        x=None, y=None,\n",
    "        mag_inst=None, e_mag_inst=None,\n",
    "        mag_cat=None, e_mag_cat=None,\n",
    "        mag_cal=None, e_mag_cal=None,\n",
    "        flag=None, is_crowded=False, is_border=False,\n",
    "        is_detection=False, separation_arcsec=None,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with open(filepath, \"r\") as fh:\n",
    "            lines = fh.readlines()\n",
    "    except OSError:\n",
    "        return None\n",
    "\n",
    "    # ── header metadata ──────────────────────────────────────────────────\n",
    "    for line in lines:\n",
    "        if not line.startswith(\"#\"):\n",
    "            break\n",
    "        if \"OBJECT:\" in line:\n",
    "            rec[\"OBJECT\"] = line.split(\"OBJECT:\")[1].strip()\n",
    "        elif \"DATE-OBS:\" in line:\n",
    "            rec[\"DATE_OBS\"] = line.split(\"DATE-OBS:\")[1].strip()\n",
    "        elif \"EXPTIME:\" in line:\n",
    "            try:\n",
    "                rec[\"EXPTIME\"] = float(\n",
    "                    line.split(\"EXPTIME:\")[1].replace(\"s\", \"\").strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "        elif \"Filter:\" in line:\n",
    "            rec[\"Filter\"] = line.split(\"Filter:\")[1].strip()\n",
    "        elif \"Image type:\" in line:\n",
    "            itype = line.split(\"Image type:\")[1].strip()\n",
    "            if itype.startswith(\"COADD\"):\n",
    "                rec[\"image_type\"] = \"COADD\"\n",
    "                try:\n",
    "                    rec[\"ncoadd\"] = int(\n",
    "                        itype.split(\"(\")[1].split(\"frame\")[0].strip())\n",
    "                except (ValueError, IndexError):\n",
    "                    pass\n",
    "            else:\n",
    "                rec[\"image_type\"] = \"SINGLE\"\n",
    "        elif \"Zeropoint:\" in line and \"+/-\" in line:\n",
    "            try:\n",
    "                zp, ze = line.split(\"Zeropoint:\")[1].strip().split(\"+/-\")\n",
    "                rec[\"Zeropoint\"] = float(zp.strip())\n",
    "                rec[\"ZP_err\"] = float(ze.replace(\"mag\", \"\").strip())\n",
    "            except (ValueError, IndexError):\n",
    "                pass\n",
    "        elif \"RMS residuals:\" in line:\n",
    "            try:\n",
    "                rec[\"RMS_residuals\"] = float(\n",
    "                    line.split(\"RMS residuals:\")[1].replace(\"mag\", \"\").strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "        elif \"RMS quality:\" in line:\n",
    "            rec[\"RMS_quality\"] = line.split(\"RMS quality:\")[1].strip()\n",
    "        elif \"ZP_check:\" in line:\n",
    "            rec[\"ZP_check\"] = line.split(\"ZP_check:\")[1].strip()\n",
    "        elif \"Calibration stars:\" in line:\n",
    "            try:\n",
    "                rec[\"Calibration_stars\"] = int(\n",
    "                    line.split(\"Calibration stars:\")[1].strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "        elif \"Stars rejected:\" in line:\n",
    "            try:\n",
    "                pct = line.split(\"(\")[1].split(\"%\")[0]\n",
    "                rec[\"Stars_rejected_frac\"] = float(pct) / 100.0\n",
    "            except (ValueError, IndexError):\n",
    "                pass\n",
    "        elif \"Rejection quality:\" in line:\n",
    "            rec[\"Rejection_quality\"] = line.split(\"Rejection quality:\")[1].strip()\n",
    "        elif \"MagLim\" in line:\n",
    "            try:\n",
    "                rec[\"Limiting_mag\"] = float(\n",
    "                    line.split(\":\")[1].replace(\"mag\", \"\").strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    # ── OBJECT filter (early exit) ───────────────────────────────────────\n",
    "    if target_objects and rec[\"OBJECT\"] not in target_objects:\n",
    "        return None\n",
    "\n",
    "    # ── Image type filter (early exit) ───────────────────────────────────\n",
    "    if image_types and rec[\"image_type\"] not in image_types:\n",
    "        return None\n",
    "\n",
    "    # ── find closest source within tolerance ─────────────────────────────\n",
    "    cos_dec  = np.cos(np.radians(target_dec))\n",
    "    best_sep = np.inf\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        cols = line.strip().split()\n",
    "        if len(cols) < 11:\n",
    "            continue\n",
    "        try:\n",
    "            ra  = float(cols[0])\n",
    "            dec = float(cols[1])\n",
    "            sep = np.hypot((ra - target_ra) * cos_dec * 3600,\n",
    "                           (dec - target_dec) * 3600)\n",
    "            if sep < tolerance_arcsec and sep < best_sep:\n",
    "                best_sep                 = sep\n",
    "                rec[\"x\"]                 = float(cols[2])\n",
    "                rec[\"y\"]                 = float(cols[3])\n",
    "                rec[\"mag_inst\"]          = float(cols[4])\n",
    "                rec[\"e_mag_inst\"]        = float(cols[5])\n",
    "                rec[\"mag_cat\"]           = float(cols[6])\n",
    "                rec[\"e_mag_cat\"]         = float(cols[7])\n",
    "                rec[\"mag_cal\"]           = float(cols[8])\n",
    "                rec[\"e_mag_cal\"]         = float(cols[9])\n",
    "                rec[\"flag\"]              = int(cols[10])\n",
    "                rec[\"is_crowded\"]        = rec[\"flag\"] in (1, 3)\n",
    "                rec[\"is_border\"]         = rec[\"flag\"] in (2, 3)\n",
    "                rec[\"is_detection\"]      = True\n",
    "                rec[\"separation_arcsec\"] = sep\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "\n",
    "    # ── demote noisy detections to upper limits ──────────────────────────\n",
    "    if rec[\"is_detection\"] and rec[\"e_mag_cal\"] > max_mag_error:\n",
    "        rec[\"is_detection\"] = False\n",
    "\n",
    "    # ── fill non-detections with limiting magnitude ──────────────────────\n",
    "    if not rec[\"is_detection\"] and rec[\"Limiting_mag\"] is not None:\n",
    "        rec[\"mag_cal\"]   = rec[\"Limiting_mag\"]\n",
    "        rec[\"e_mag_cal\"] = 0.0\n",
    "\n",
    "    return rec\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Collect photometry files\n",
    "# =============================================================================\n",
    "\n",
    "if RECURSIVE:\n",
    "    pattern = os.path.join(INPUT_FOLDER, \"**\", \"reduced\", \"*_photometry.txt\")\n",
    "    phot_files = sorted(glob.glob(pattern, recursive=True))\n",
    "else:\n",
    "    pattern = os.path.join(INPUT_FOLDER, \"reduced\", \"*_photometry.txt\")\n",
    "    phot_files = sorted(glob.glob(pattern))\n",
    "\n",
    "print(f\"Target : RA = {TARGET_RA:.6f}°  DEC = {TARGET_DEC:.6f}°  \"\n",
    "      f\"tolerance = {TOLERANCE_ARCSEC}″\")\n",
    "print(f\"Mode   : {'recursive' if RECURSIVE else 'single folder'}\")\n",
    "if TARGET_OBJECTS:\n",
    "    print(f\"OBJECT filter : {TARGET_OBJECTS}\")\n",
    "if IMAGE_TYPES:\n",
    "    print(f\"Image type    : {IMAGE_TYPES}\")\n",
    "print(f\"Found {len(phot_files)} photometry files\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Parse and cross-match\n",
    "# =============================================================================\n",
    "\n",
    "rows = []\n",
    "for fp in phot_files:\n",
    "    rec = parse_photometry_file(fp, TARGET_RA, TARGET_DEC,\n",
    "                                TOLERANCE_ARCSEC, MAX_MAG_ERROR,\n",
    "                                TARGET_OBJECTS, IMAGE_TYPES)\n",
    "    if rec and rec[\"DATE_OBS\"] and rec[\"mag_cal\"] is not None:\n",
    "        rows.append(rec)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Add time columns and save\n",
    "# =============================================================================\n",
    "\n",
    "df[\"datetime\"]  = pd.to_datetime(df[\"DATE_OBS\"])\n",
    "df[\"MJD\"]       = df[\"DATE_OBS\"].apply(\n",
    "    lambda x: Time(x, format=\"isot\").mjd if x else np.nan)\n",
    "df[\"MJD_rel\"]   = df[\"MJD\"] - df[\"MJD\"].min()       # days since first epoch\n",
    "df[\"hours_rel\"] = df[\"MJD_rel\"] * 24.0                # hours since first epoch\n",
    "\n",
    "df = df.sort_values(\"MJD\").reset_index(drop=True)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Summary\n",
    "# =============================================================================\n",
    "\n",
    "n_det = df[\"is_detection\"].sum()\n",
    "print(f\"Detections   : {n_det}\")\n",
    "print(f\"Upper limits : {len(df) - n_det}\")\n",
    "print(f\"Objects      : {sorted(df['OBJECT'].dropna().unique())}\")\n",
    "print(f\"Filters      : {sorted(df['Filter'].dropna().unique())}\")\n",
    "\n",
    "if \"image_type\" in df.columns and df[\"image_type\"].notna().any():\n",
    "    n_coadd  = (df[\"image_type\"] == \"COADD\").sum()\n",
    "    n_single = (df[\"image_type\"] == \"SINGLE\").sum()\n",
    "    print(f\"Image types  : {n_coadd} coadds, {n_single} single frames\")\n",
    "\n",
    "print(f\"Time span    : MJD {df['MJD'].min():.4f} – {df['MJD'].max():.4f}  \"\n",
    "      f\"({df['MJD_rel'].max():.2f} days)\")\n",
    "print(f\"Saved to     : {OUTPUT_CSV}\\n\")\n",
    "\n",
    "# Flags summary\n",
    "if \"flag\" in df.columns and df[\"flag\"].notna().any():\n",
    "    det = df[df[\"is_detection\"]]\n",
    "    n_clean  = (det[\"flag\"] == 0).sum()\n",
    "    n_crowd  = det[\"is_crowded\"].sum()\n",
    "    n_border = det[\"is_border\"].sum()\n",
    "    print(f\"Detection quality flags:\")\n",
    "    print(f\"  Isolated+central (flag=0)  : {n_clean}\")\n",
    "    print(f\"  Crowded          (flag 1/3): {n_crowd}\")\n",
    "    print(f\"  Border           (flag 2/3): {n_border}\\n\")\n",
    "\n",
    "display(df[[\"datetime\", \"MJD\", \"MJD_rel\", \"OBJECT\", \"Filter\",\n",
    "            \"image_type\", \"ncoadd\", \"EXPTIME\",\n",
    "            \"mag_cal\", \"e_mag_cal\", \"is_detection\", \"flag\",\n",
    "            \"is_crowded\", \"is_border\", \"RMS_quality\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d87c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fcf67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
